{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Example of using [`vtreat`](https://github.com/WinVector/pyvtreat) inside a sklearn pipeline.\n",
    "\n",
    "This note is to bring out that while `vtreat` can be placed in such pipelines, one should not place it in pipelines used for hyperparameters search.  Intead during hyperparameters search we advise treating `vtreat` as a separate pre-processing step. If one wishes to play with different variable filter parameters, we suggest allowing `vtreat` to land excess variables and then filtering at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our demonstration we first load packages/modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import numpy.random\n",
    "import vtreat\n",
    "import vtreat.util\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set our pseudorandom state to improve reproducibilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We new build our example training data.  It is designed to be a data set with categorical variables where common levels are informative and rare levels are not.  So setting at what rarity levels are encoded can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(nrows, \n",
    "              *,\n",
    "              ncols=10,\n",
    "              n_common_levels=5,\n",
    "              n_rare_levels=10,\n",
    "              rare_ratio=0.3,\n",
    "              noise_magnitude=3.3,\n",
    "              na_rate=0.1):\n",
    "    # build a system of more common levels, which have signal,\n",
    "    # and rare levels, which do not have signal\n",
    "    common_levels = ['c_' + str(i) for i in range(n_common_levels)]\n",
    "    rare_levels = ['r_' + str(i) for i in range(n_rare_levels)]\n",
    "    levels = common_levels + rare_levels\n",
    "    probs = numpy.asarray([1.0 / len(common_levels)] * len(common_levels) + \n",
    "                          [rare_ratio / len(rare_levels)] * len(rare_levels))\n",
    "    probs = probs / sum(probs)\n",
    "    effects = numpy.random.choice(\n",
    "        [-1, 1], \n",
    "        size = len(common_levels), \n",
    "        replace=True).tolist() + [0]*len(rare_levels)\n",
    "    effects = {li: ei for (li, ei) in zip(levels, effects)}\n",
    "    # use this to populate up a data frame\n",
    "    d = pandas.DataFrame({\n",
    "        'x_' + str(i): numpy.random.choice(levels, \n",
    "                                           size=nrows, \n",
    "                                           replace=True, \n",
    "                                           p=probs) for i in range(ncols)\n",
    "    })\n",
    "    # build y\n",
    "    y = noise_magnitude * numpy.random.normal(size=nrows)\n",
    "    for i in range(ncols):\n",
    "        y = y + d[d.columns[i]].map(effects)\n",
    "    # introduce some NaNs\n",
    "    if na_rate > 0:\n",
    "        for i in range(ncols):\n",
    "            idx = numpy.where(\n",
    "                numpy.random.choice([False, True], \n",
    "                                    size=nrows, \n",
    "                                    replace=True, \n",
    "                                    p=[1 - na_rate, na_rate]))[0]\n",
    "            if len(idx) > 0:\n",
    "                d.loc[idx, d.columns[i]] = numpy.nan\n",
    "    return d, y > 0\n",
    "\n",
    "d_x, d_y = make_data(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   x_0  x_1  x_2  x_3  x_4  x_5  x_6  x_7  x_8  x_9\n0  c_3  c_1  NaN  r_8  r_3  c_0  c_2  r_3  c_4  c_1\n1  c_3  NaN  r_9  c_3  c_3  c_1  c_2  c_3  c_0  c_3\n2  NaN  c_3  c_4  c_0  c_1  r_0  c_1  r_9  c_3  c_0\n3  c_4  c_2  c_3  r_9  c_0  r_0  r_7  c_1  c_2  r_1\n4  c_2  c_1  r_1  NaN  c_1  c_3  c_4  c_3  c_0  c_0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x_0</th>\n      <th>x_1</th>\n      <th>x_2</th>\n      <th>x_3</th>\n      <th>x_4</th>\n      <th>x_5</th>\n      <th>x_6</th>\n      <th>x_7</th>\n      <th>x_8</th>\n      <th>x_9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c_3</td>\n      <td>c_1</td>\n      <td>NaN</td>\n      <td>r_8</td>\n      <td>r_3</td>\n      <td>c_0</td>\n      <td>c_2</td>\n      <td>r_3</td>\n      <td>c_4</td>\n      <td>c_1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c_3</td>\n      <td>NaN</td>\n      <td>r_9</td>\n      <td>c_3</td>\n      <td>c_3</td>\n      <td>c_1</td>\n      <td>c_2</td>\n      <td>c_3</td>\n      <td>c_0</td>\n      <td>c_3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>c_3</td>\n      <td>c_4</td>\n      <td>c_0</td>\n      <td>c_1</td>\n      <td>r_0</td>\n      <td>c_1</td>\n      <td>r_9</td>\n      <td>c_3</td>\n      <td>c_0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c_4</td>\n      <td>c_2</td>\n      <td>c_3</td>\n      <td>r_9</td>\n      <td>c_0</td>\n      <td>r_0</td>\n      <td>r_7</td>\n      <td>c_1</td>\n      <td>c_2</td>\n      <td>r_1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c_2</td>\n      <td>c_1</td>\n      <td>r_1</td>\n      <td>NaN</td>\n      <td>c_1</td>\n      <td>c_3</td>\n      <td>c_4</td>\n      <td>c_3</td>\n      <td>c_0</td>\n      <td>c_0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    False\n1     True\n2     True\n3     True\n4    False\ndtype: bool"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vtreat` can be placed in a `scikit` `Pipeline` to be part of a reusable processing workflow.  However, it is *not* recommended to use such a pipeline for hyper-parameter search, as by design `vtreat` has very few tunable parameters (mostly just `indicator_min_fraction`), `vtreat` has its own out of sample simulation, and it is quite wasteful to re-compute similar data re-encodings again and again. Our advice is: treat `vtreat` as an early non-tuned pre-processing step and re-use its work in later pipelines \n",
    "\n",
    "To even place `vtreat` into hyperparameter search we need an adapter class that hides the non-tunable parameters. `vtreat`'s bundling of parameters into a re-usable object isn't compatible with the clone-step many hyper parameter searches use. `vtreat` does implement `get_parameters()` and `set_parameters()`, but for neatness it doesn't expose each individual possible setting a explicit constructor arugments (prefering a params object).\n",
    "\n",
    "`vtreat` does try and support hyper-parameter tuning: for example it defaults to re-using cross validation plans where possible to de-noise the type of repeated application we may see in hyper-parameter optimization.\n",
    "\n",
    "The additional adaption is easy and can be performed as follows.  Remember this adaption is not recommended. Instructions how to use `vtreat` can be found [here](https://github.com/WinVector/pyvtreat/blob/main/Examples/Classification/Classification.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinomialOutcomeTreatmentP(vtreat.BinomialOutcomeTreatment):\n",
    "    \"\"\"bind in non-tuned parmeters for when grid search clones\"\"\"\n",
    "    \n",
    "    def __init__(self, *, indicator_min_fraction=0.1):\n",
    "        vtreat.BinomialOutcomeTreatment.__init__(\n",
    "            self,\n",
    "            outcome_target=True,\n",
    "            params = {\n",
    "                'filter_to_recommended': False,\n",
    "                'indicator_min_fraction': indicator_min_fraction,\n",
    "                'coders': {'indicator_code'},\n",
    "            }\n",
    "        )\n",
    "\n",
    "transform = BinomialOutcomeTreatmentP()\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', transform),\n",
    "    ('classifier', LogisticRegression(solver = 'lbfgs'))]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(d_x, d_y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a [cross-validated grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) for hyper parameters, including the indicator coding strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'preprocessor__indicator_min_fraction': [0.01, 0.1],\n",
    "    'classifier__C': [0.1, 1],\n",
    "}\n",
    "\n",
    "cgm = GridSearchCV(clf, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('preprocessor',\n                                        __main__.BinomialOutcomeTreatmentP(outcome_target=True, )),\n                                       ('classifier', LogisticRegression())]),\n             param_grid={'classifier__C': [0.1, 1],\n                         'preprocessor__indicator_min_fraction': [0.01, 0.1]})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'classifier__C': 0.1, 'preprocessor__indicator_min_fraction': 0.1}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_fit_time': array([0.71360078, 0.28696437, 0.68817482, 0.28684545]),\n 'std_fit_time': array([0.03392186, 0.00624858, 0.01178248, 0.01096785]),\n 'mean_score_time': array([0.07794299, 0.03840861, 0.07571516, 0.0383904 ]),\n 'std_score_time': array([0.00166816, 0.00067049, 0.00099838, 0.00055073]),\n 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1],\n              mask=[False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'param_preprocessor__indicator_min_fraction': masked_array(data=[0.01, 0.1, 0.01, 0.1],\n              mask=[False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'params': [{'classifier__C': 0.1,\n   'preprocessor__indicator_min_fraction': 0.01},\n  {'classifier__C': 0.1, 'preprocessor__indicator_min_fraction': 0.1},\n  {'classifier__C': 1, 'preprocessor__indicator_min_fraction': 0.01},\n  {'classifier__C': 1, 'preprocessor__indicator_min_fraction': 0.1}],\n 'split0_test_score': array([0.7  , 0.735, 0.66 , 0.72 ]),\n 'split1_test_score': array([0.735, 0.725, 0.725, 0.75 ]),\n 'split2_test_score': array([0.72 , 0.705, 0.675, 0.67 ]),\n 'split3_test_score': array([0.72 , 0.725, 0.71 , 0.715]),\n 'split4_test_score': array([0.68 , 0.685, 0.67 , 0.7  ]),\n 'mean_test_score': array([0.711, 0.715, 0.688, 0.711]),\n 'std_test_score': array([0.01907878, 0.01788854, 0.02501999, 0.02615339]),\n 'rank_test_score': array([2, 1, 4, 3], dtype=int32)}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7150000000000001"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    mean_test_score  \\\nclassifier__C preprocessor__indicator_min_fraction                    \n0.1           0.01                                            0.711   \n              0.10                                            0.715   \n1.0           0.01                                            0.688   \n              0.10                                            0.711   \n\n                                                    rank_test_score  \\\nclassifier__C preprocessor__indicator_min_fraction                    \n0.1           0.01                                                2   \n              0.10                                                1   \n1.0           0.01                                                4   \n              0.10                                                3   \n\n                                                    std_test_score  \nclassifier__C preprocessor__indicator_min_fraction                  \n0.1           0.01                                        0.019079  \n              0.10                                        0.017889  \n1.0           0.01                                        0.025020  \n              0.10                                        0.026153  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>mean_test_score</th>\n      <th>rank_test_score</th>\n      <th>std_test_score</th>\n    </tr>\n    <tr>\n      <th>classifier__C</th>\n      <th>preprocessor__indicator_min_fraction</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">0.1</th>\n      <th>0.01</th>\n      <td>0.711</td>\n      <td>2</td>\n      <td>0.019079</td>\n    </tr>\n    <tr>\n      <th>0.10</th>\n      <td>0.715</td>\n      <td>1</td>\n      <td>0.017889</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1.0</th>\n      <th>0.01</th>\n      <td>0.688</td>\n      <td>4</td>\n      <td>0.025020</td>\n    </tr>\n    <tr>\n      <th>0.10</th>\n      <td>0.711</td>\n      <td>3</td>\n      <td>0.026153</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_names = list(cgm.cv_results_['params'][0].keys())\n",
    "perf_cols = {\n",
    "    p: [cgm.cv_results_['params'][i][p] for \n",
    "          i in range(len(cgm.cv_results_['params']))] for p \n",
    "            in param_names\n",
    "    }\n",
    "perf_cols.update({\n",
    "        'mean_test_score': cgm.cv_results_['mean_test_score'],\n",
    "        'rank_test_score': cgm.cv_results_['rank_test_score'],\n",
    "        'std_test_score': cgm.cv_results_['std_test_score'],\n",
    "    })\n",
    "perf_frame = pandas.DataFrame(perf_cols)\n",
    "perf_frame.set_index(param_names, inplace=True)\n",
    "perf_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `preprocessor__indicator_min_fraction` was chosen to be `0.1`. This a good setting, as it allows in the non-informative rare levels.\n",
    "\n",
    "We can confirm this by evaluating the model by heand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.706"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(preprocessor__indicator_min_fraction=0.01)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above we are using the held-out test data to ensure a reliable estimate of the model quality.  The grid search used cross-validation (both in `vtreat` and in the grid search component) to ensure the same.  Let's also look at this model's performance on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmount/Documents/work/pyvtreat/pkg/vtreat/vtreat_api.py:273: UserWarning: possibly called transform on same data used to fit\n",
      "(this causes over-fit, please use fit_transform() instead)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.786"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice `vtreat` generates a warning that the same data was used to both design the variable treatment and treat data (leading to nested model bias).  All the use has to do to avoid this bias is call `.fit_transform(X_train, y_train)` on vtreat intead of calling `.fit(X_train, y_train).transform(X_train)`.  The absence of a warning message helps confirm the user has not done this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also confirm this `indicator_min_fraction=0.01` setting lets in very many variables, including the non-informative `lev_r` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0      x_0_lev_c_3\n1      x_0_lev_c_1\n2      x_0_lev_c_4\n3      x_0_lev_c_0\n4      x_0_lev_c_2\n          ...     \n154    x_3_lev_r_6\n155    x_3_lev_r_8\n156    x_3_lev_r_7\n157    x_3_lev_r_2\n158    x_3_lev_r_0\nName: variable, Length: 159, dtype: object"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.score_frame_['variable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at `indicator_min_fraction=0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.721"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(preprocessor__indicator_min_fraction=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a slighly better out of sample score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmount/Documents/work/pyvtreat/pkg/vtreat/vtreat_api.py:273: UserWarning: possibly called transform on same data used to fit\n",
      "(this causes over-fit, please use fit_transform() instead)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.755"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The in-sample score is larger for this worse parameter choice. Over-fit by evaluating on training data perfers the excess variables even though they are useless.  This is why the grid search cross-validates in addition to `vtreat`'s use of out of sample procedures.\n",
    "\n",
    "We can confirm there are fewer variables for this setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0      x_0_lev_c_3\n1      x_0_lev_c_1\n2      x_0_lev_c_4\n3      x_0_lev_c_0\n4      x_0_lev_c_2\n5      x_4_lev_c_2\n6      x_4_lev_c_0\n7      x_4_lev_c_1\n8      x_4_lev_c_3\n9      x_4_lev_c_4\n10    x_4_lev__NA_\n11     x_8_lev_c_2\n12     x_8_lev_c_3\n13     x_8_lev_c_4\n14     x_8_lev_c_1\n15     x_8_lev_c_0\n16     x_5_lev_c_3\n17     x_5_lev_c_4\n18     x_5_lev_c_0\n19     x_5_lev_c_1\n20     x_5_lev_c_2\n21     x_9_lev_c_1\n22     x_9_lev_c_0\n23     x_9_lev_c_2\n24     x_9_lev_c_4\n25     x_9_lev_c_3\n26    x_9_lev__NA_\n27     x_2_lev_c_0\n28     x_2_lev_c_1\n29     x_2_lev_c_4\n30     x_2_lev_c_2\n31     x_2_lev_c_3\n32    x_2_lev__NA_\n33     x_1_lev_c_3\n34     x_1_lev_c_0\n35     x_1_lev_c_1\n36     x_1_lev_c_4\n37     x_1_lev_c_2\n38    x_1_lev__NA_\n39     x_7_lev_c_0\n40     x_7_lev_c_1\n41     x_7_lev_c_4\n42     x_7_lev_c_2\n43     x_7_lev_c_3\n44    x_7_lev__NA_\n45     x_6_lev_c_3\n46     x_6_lev_c_1\n47     x_6_lev_c_4\n48     x_6_lev_c_2\n49     x_6_lev_c_0\n50     x_3_lev_c_1\n51     x_3_lev_c_0\n52     x_3_lev_c_2\n53     x_3_lev_c_4\n54     x_3_lev_c_3\nName: variable, dtype: object"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.score_frame_['variable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point is: putting `vtreat` into the hyper-parameters search is expensive. And it may not be reliable as settings of other variable supression steps (such as the `C` and other regularization details) can mask the value of `vtreat`'s variable pruning.  Variables that the model knows to turn off, don't cause problems.\n",
    "\n",
    "This is also why we don't consider `vtreat`'s pruning a detailed hyper-parameter. As long as it is set to not \"blow up too much\" we expect modern regularized methods to tolerate a great variation in the setting. \n",
    "\n",
    "Or: \n",
    "  * The less sensitive we are to a parameter the less it matters if we are exactly at the optimal setting.\n",
    "  * Parameters are more difficult to optimize if we are less sensitive to them.\n",
    "  \n",
    "We have shown a sucessful operation of `vtreat` in hyper-parameter search.  However in the end we do not recommend this workflow as:\n",
    "\n",
    "  * It is needlessly expensive, as it re-does many nearly identical variable-prep steps.\n",
    "  * It may not be needed as one may be able to pick \"good enough a parameters ahead of time.\n",
    "  * It may not set better parameters, as downstream regularization may obscure the correct settings.\n",
    "  \n",
    "The workflow we recommend is more like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['x_0_lev_c_3', 'x_4_logit_code', 'x_4_lev_c_3', 'x_8_logit_code',\n       'x_8_lev_c_2', 'x_8_lev_c_4', 'x_8_lev_c_1', 'x_8_lev_c_0',\n       'x_5_logit_code', 'x_5_lev_c_3', 'x_5_lev_c_4', 'x_5_lev_c_0',\n       'x_5_lev_c_2', 'x_9_logit_code', 'x_9_lev_c_1', 'x_9_lev_c_4',\n       'x_9_lev_c_3', 'x_2_logit_code', 'x_2_lev_c_1', 'x_2_lev_c_2',\n       'x_1_logit_code', 'x_1_lev_c_4', 'x_7_logit_code', 'x_7_lev_c_0',\n       'x_7_lev_c_2', 'x_7_lev_c_3', 'x_6_logit_code', 'x_3_logit_code',\n       'x_3_prevalence_code', 'x_3_lev_c_2', 'x_3_lev_c_3'],\n      dtype='object')"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = vtreat.BinomialOutcomeTreatment(\n",
    "            outcome_target=True,\n",
    "            params = {\n",
    "                'filter_to_recommended': True,\n",
    "                'indicator_min_fraction': 0.1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "X_train_treated = transform.fit_transform(X_train, y_train)\n",
    "\n",
    "X_train_treated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'classifier__C': 0.1}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline(steps=[\n",
    "    ('classifier', LogisticRegression(solver = 'lbfgs'))]\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'classifier__C': [0.1, 1],\n",
    "}\n",
    "\n",
    "cgm = GridSearchCV(clf, parameters, cv=5)\n",
    "\n",
    "cgm.fit(X_train_treated, y_train)\n",
    "\n",
    "cgm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.713"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = cgm.best_estimator_\n",
    "\n",
    "X_test_treated = transform.transform(X_test)\n",
    "\n",
    "est.score(X_test_treated, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this didn't achieve the optimal score (likely the `'filter_to_recommended': True` was too strict).  But it is in the ballpark and improves as we get more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}