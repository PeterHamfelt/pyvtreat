{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Example of using [`vtreat`](https://github.com/WinVector/pyvtreat) inside a sklearn pipeline.\n",
    "\n",
    "This note is to bring out that while `vtreat` can be placed in such pipelines, one should not place it in pipelines used for hyperparameters search.  Intead during hyperparameters search we advise treating `vtreat` as a separate pre-processing step. If one wishes to play with different variable filter parameters, we suggest allowing `vtreat` to land excess variables and then filtering at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our demonstration we first load packages/modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import numpy.random\n",
    "import vtreat\n",
    "import vtreat.util\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set our pseudorandom state to improve reproducibilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We new build our example training data.  It is designed to be a data set with categorical variables where common levels are informative and rare levels are not.  So setting at what rarity levels are encoded can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def make_data(nrows, \n",
    "              *,\n",
    "              ncols=10,\n",
    "              n_common_levels=5,\n",
    "              n_rare_levels=10,\n",
    "              rare_ratio=0.3,\n",
    "              noise_magnitude=3.3,\n",
    "              na_rate=0.1):\n",
    "    # build a system of more common levels, which have signal,\n",
    "    # and rare levels, which do not have signal\n",
    "    common_levels = ['c_' + str(i) for i in range(n_common_levels)]\n",
    "    rare_levels = ['r_' + str(i) for i in range(n_rare_levels)]\n",
    "    levels = common_levels + rare_levels\n",
    "    probs = numpy.asarray([1.0 / len(common_levels)] * len(common_levels) + \n",
    "                          [rare_ratio / len(rare_levels)] * len(rare_levels))\n",
    "    probs = probs / sum(probs)\n",
    "    effects = numpy.random.choice(\n",
    "        [-1, 1], \n",
    "        size = len(common_levels), \n",
    "        replace=True).tolist() + [0]*len(rare_levels)\n",
    "    effects = {li: ei for (li, ei) in zip(levels, effects)}\n",
    "    # use this to populate up a data frame\n",
    "    d = pandas.DataFrame({\n",
    "        'x_' + str(i): numpy.random.choice(levels, \n",
    "                                           size=nrows, \n",
    "                                           replace=True, \n",
    "                                           p=probs) for i in range(ncols)\n",
    "    })\n",
    "    # build y\n",
    "    y = noise_magnitude * numpy.random.normal(size=nrows)\n",
    "    for i in range(ncols):\n",
    "        y = y + d[d.columns[i]].map(effects)\n",
    "    # introduce some NaNs\n",
    "    if na_rate > 0:\n",
    "        for i in range(ncols):\n",
    "            idx = numpy.where(\n",
    "                numpy.random.choice([False, True], \n",
    "                                    size=nrows, \n",
    "                                    replace=True, \n",
    "                                    p=[1 - na_rate, na_rate]))[0]\n",
    "            if len(idx) > 0:\n",
    "                d.loc[idx, d.columns[i]] = numpy.nan\n",
    "    return d, y > 0\n",
    "\n",
    "d_x, d_y = make_data(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_3</td>\n",
       "      <td>c_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r_8</td>\n",
       "      <td>r_3</td>\n",
       "      <td>c_0</td>\n",
       "      <td>c_2</td>\n",
       "      <td>r_3</td>\n",
       "      <td>c_4</td>\n",
       "      <td>c_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r_9</td>\n",
       "      <td>c_3</td>\n",
       "      <td>c_3</td>\n",
       "      <td>c_1</td>\n",
       "      <td>c_2</td>\n",
       "      <td>c_3</td>\n",
       "      <td>c_0</td>\n",
       "      <td>c_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>c_3</td>\n",
       "      <td>c_4</td>\n",
       "      <td>c_0</td>\n",
       "      <td>c_1</td>\n",
       "      <td>r_0</td>\n",
       "      <td>c_1</td>\n",
       "      <td>r_9</td>\n",
       "      <td>c_3</td>\n",
       "      <td>c_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_4</td>\n",
       "      <td>c_2</td>\n",
       "      <td>c_3</td>\n",
       "      <td>r_9</td>\n",
       "      <td>c_0</td>\n",
       "      <td>r_0</td>\n",
       "      <td>r_7</td>\n",
       "      <td>c_1</td>\n",
       "      <td>c_2</td>\n",
       "      <td>r_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_2</td>\n",
       "      <td>c_1</td>\n",
       "      <td>r_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c_1</td>\n",
       "      <td>c_3</td>\n",
       "      <td>c_4</td>\n",
       "      <td>c_3</td>\n",
       "      <td>c_0</td>\n",
       "      <td>c_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_0  x_1  x_2  x_3  x_4  x_5  x_6  x_7  x_8  x_9\n",
       "0  c_3  c_1  NaN  r_8  r_3  c_0  c_2  r_3  c_4  c_1\n",
       "1  c_3  NaN  r_9  c_3  c_3  c_1  c_2  c_3  c_0  c_3\n",
       "2  NaN  c_3  c_4  c_0  c_1  r_0  c_1  r_9  c_3  c_0\n",
       "3  c_4  c_2  c_3  r_9  c_0  r_0  r_7  c_1  c_2  r_1\n",
       "4  c_2  c_1  r_1  NaN  c_1  c_3  c_4  c_3  c_0  c_0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "3     True\n",
       "4    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vtreat` can be placed in a `scikit` `Pipeline` to be part of a reusable processing workflow.  However, it is *not* recommended to use such a pipeline for hyper-parameter search, as by design `vtreat` has very few tunable parameters (mostly just `indicator_min_fraction`), `vtreat` has its own out of sample simulation, and it is quite wasteful to re-compute similar data re-encodings again and again. Our advice is: treat `vtreat` as an early non-tuned pre-processing step and re-use its work in later pipelines \n",
    "\n",
    "To even place `vtreat` into hyperparameter search we need an adapter class that hides the non-tunable parameters. `vtreat`'s bundling of parameters into a re-usable object isn't compatible with the clone-step many hyper parameter searches use. `vtreat` does implement `get_parameters()` and `set_parameters()`, but for neatness it doesn't expose each individual possible setting a explicit constructor arugments (prefering a params object).\n",
    "\n",
    "The adaption is easy and can be performed as follows.  Remember this adaption is not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinomialOutcomeTreatmentP(vtreat.BinomialOutcomeTreatment):\n",
    "    \"\"\"bind in non-tuned parmeters for when grid search clones\"\"\"\n",
    "    \n",
    "    def __init__(self, *, indicator_min_fraction=0.1):\n",
    "        vtreat.BinomialOutcomeTreatment.__init__(\n",
    "            self,\n",
    "            outcome_target=True,\n",
    "            params = {\n",
    "                'filter_to_recommended': False,\n",
    "                'indicator_min_fraction': indicator_min_fraction,\n",
    "            }\n",
    "        )\n",
    "\n",
    "transform = BinomialOutcomeTreatmentP()\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', transform),\n",
    "    ('classifier', LogisticRegression(solver = 'lbfgs'))]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(d_x, d_y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a [cross-validated grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) for hyper parameters, including the indicator coding strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'preprocessor__indicator_min_fraction': [0.01, 0.1],\n",
    "    'classifier__C': [0.1, 1],\n",
    "}\n",
    "\n",
    "cgm = GridSearchCV(clf, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        __main__.BinomialOutcomeTreatmentP(outcome_target=True, )),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(C=1.0,\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'classifier__C': [0.1, 1],\n",
       "                         'preprocessor__indicator_min_fraction': [0.01, 0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1, 'preprocessor__indicator_min_fraction': 0.1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.19765596, 2.89098158, 2.87480154, 2.40274677]),\n",
       " 'std_fit_time': array([1.26430386, 0.67445223, 0.033196  , 0.21584406]),\n",
       " 'mean_score_time': array([0.42749877, 0.24598446, 0.31875601, 0.22581787]),\n",
       " 'std_score_time': array([0.11181476, 0.04447459, 0.01104469, 0.00743607]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocessor__indicator_min_fraction': masked_array(data=[0.01, 0.1, 0.01, 0.1],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'preprocessor__indicator_min_fraction': 0.01},\n",
       "  {'classifier__C': 0.1, 'preprocessor__indicator_min_fraction': 0.1},\n",
       "  {'classifier__C': 1, 'preprocessor__indicator_min_fraction': 0.01},\n",
       "  {'classifier__C': 1, 'preprocessor__indicator_min_fraction': 0.1}],\n",
       " 'split0_test_score': array([0.705, 0.73 , 0.68 , 0.735]),\n",
       " 'split1_test_score': array([0.73 , 0.745, 0.73 , 0.76 ]),\n",
       " 'split2_test_score': array([0.72 , 0.695, 0.68 , 0.685]),\n",
       " 'split3_test_score': array([0.71 , 0.705, 0.72 , 0.695]),\n",
       " 'split4_test_score': array([0.67 , 0.685, 0.675, 0.685]),\n",
       " 'mean_test_score': array([0.707, 0.712, 0.697, 0.712]),\n",
       " 'std_test_score': array([0.02039608, 0.02227106, 0.02315167, 0.03026549]),\n",
       " 'rank_test_score': array([3, 1, 4, 1], dtype=int32)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.712"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>indicator_min_fraction</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.707</td>\n",
       "      <td>3</td>\n",
       "      <td>0.020396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.697</td>\n",
       "      <td>4</td>\n",
       "      <td>0.023152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     C  indicator_min_fraction  mean_test_score  rank_test_score  \\\n",
       "0  0.1                    0.01            0.707                3   \n",
       "1  0.1                    0.10            0.712                1   \n",
       "2  1.0                    0.01            0.697                4   \n",
       "3  1.0                    0.10            0.712                1   \n",
       "\n",
       "   std_test_score  \n",
       "0        0.020396  \n",
       "1        0.022271  \n",
       "2        0.023152  \n",
       "3        0.030265  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame({\n",
    "    'C': [cgm.cv_results_['params'][i]['classifier__C'] for \n",
    "          i in range(len(cgm.cv_results_['params']))],\n",
    "    'indicator_min_fraction': [cgm.cv_results_['params'][i]['preprocessor__indicator_min_fraction'] for \n",
    "                               i in range(len(cgm.cv_results_['params']))],\n",
    "    'mean_test_score': cgm.cv_results_['mean_test_score'],\n",
    "    'rank_test_score': cgm.cv_results_['rank_test_score'],\n",
    "    'std_test_score': cgm.cv_results_['std_test_score'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `preprocessor__indicator_min_fraction` was chosen to be `0.1`. This a good setting, as it allows in the non-informative rare levels.\n",
    "\n",
    "We can confirm this by evaluating the model by heand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(preprocessor__indicator_min_fraction=0.01)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above we are using the held-out test data to ensure a reliable estimate of the model quality.  The grid search used cross-validation (both in `vtreat` and in the grid search component) to ensure the same.  Let's also look at this model's performance on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmount/opt/anaconda3/envs/ai_academy_3_7/lib/python3.7/site-packages/vtreat/vtreat_api.py:271: UserWarning: possibly called transform on same data used to fit\n",
      "(this causes over-fit, please use fit_transform() instead)\n",
      "  \"possibly called transform on same data used to fit\\n\" +\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.779"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice `vtreat` generates a warning that the same data was used to both design the variable treatment and treat data (leading to nested model bias).  All the use has to do to avoid this bias is call `.fit_transform(X_train, y_train)` on vtreat intead of calling `.fit(X_train, y_train).transform(X_train)`.  The absence of a warning message helps confirm the user has not done this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also confirm this `indicator_min_fraction=0.01` setting lets in very many variables, including the non-informative `lev_r` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       x_0_is_bad\n",
       "1       x_1_is_bad\n",
       "2       x_2_is_bad\n",
       "3       x_3_is_bad\n",
       "4       x_4_is_bad\n",
       "          ...     \n",
       "184    x_9_lev_r_2\n",
       "185    x_9_lev_r_9\n",
       "186    x_9_lev_r_0\n",
       "187    x_9_lev_r_3\n",
       "188    x_9_lev_r_8\n",
       "Name: variable, Length: 189, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.score_frame_['variable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at `indicator_min_fraction=0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(preprocessor__indicator_min_fraction=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a slighly better out of sample score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmount/opt/anaconda3/envs/ai_academy_3_7/lib/python3.7/site-packages/vtreat/vtreat_api.py:271: UserWarning: possibly called transform on same data used to fit\n",
      "(this causes over-fit, please use fit_transform() instead)\n",
      "  \"possibly called transform on same data used to fit\\n\" +\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.739"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The in-sample score is reversed, over-fit perfers the excess variables even though they are useless.  This is why the grid search cross-validates in addition to `vtreat`'s use of out of sample procedures.\n",
    "\n",
    "We can confirm there are fewer variables for this setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       x_0_is_bad\n",
       "1       x_1_is_bad\n",
       "2       x_2_is_bad\n",
       "3       x_3_is_bad\n",
       "4       x_4_is_bad\n",
       "          ...     \n",
       "80     x_9_lev_c_0\n",
       "81     x_9_lev_c_2\n",
       "82     x_9_lev_c_4\n",
       "83     x_9_lev_c_3\n",
       "84    x_9_lev__NA_\n",
       "Name: variable, Length: 85, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.score_frame_['variable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point is: putting `vtreat` into the hyper-parameters search is expensive. And it may not be reliable as settings of other variable supression steps (such as the `C` and other regularization details) can mask the value of `vtreat`'s variable pruning.  Variables that the model knows to turn off, don't cause problems.\n",
    "\n",
    "This is also why we don't consider `vtreat`'s pruning a detailed hyper-parameter. As long as it is set to not \"blow up too much\" we expect modern regularized methods to tolerate a great variation in the setting. \n",
    "\n",
    "Or: \n",
    "  * The less sensitive we are to a parameter the less it matters if we are exactly at the optimal setting.\n",
    "  * Parameters are more difficult to optimize if we are less sensitive to them.\n",
    "  \n",
    "We have shown a sucessful operation of `vtreat` in hyper-parameter search.  However in the end we do not recommend this workflow as:\n",
    "\n",
    "  * It is needlessly expensive, as it re-does many nearly identical variable-prep steps.\n",
    "  * It may not be needed as one may be able to pick \"good enough a parameters ahead of time.\n",
    "  * It may not set better parameters, as downstream regularization may obscure the correct settings.\n",
    "  \n",
    "The workflow we recommend is more like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x_0_lev_c_3', 'x_1_logit_code', 'x_1_lev_c_4', 'x_2_logit_code',\n",
       "       'x_2_lev_c_1', 'x_2_lev_c_2', 'x_3_logit_code', 'x_3_prevalence_code',\n",
       "       'x_3_lev_c_2', 'x_3_lev_c_3', 'x_4_logit_code', 'x_4_lev_c_3',\n",
       "       'x_5_logit_code', 'x_5_lev_c_3', 'x_5_lev_c_4', 'x_5_lev_c_0',\n",
       "       'x_5_lev_c_2', 'x_6_logit_code', 'x_7_logit_code', 'x_7_lev_c_0',\n",
       "       'x_7_lev_c_2', 'x_7_lev_c_3', 'x_8_logit_code', 'x_8_lev_c_2',\n",
       "       'x_8_lev_c_4', 'x_8_lev_c_1', 'x_8_lev_c_0', 'x_9_logit_code',\n",
       "       'x_9_lev_c_1', 'x_9_lev_c_4', 'x_9_lev_c_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = vtreat.BinomialOutcomeTreatment(\n",
    "            outcome_target=True,\n",
    "            params = {\n",
    "                'filter_to_recommended': True,\n",
    "                'indicator_min_fraction': 0.1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "X_train_treated = transform.fit_transform(X_train, y_train)\n",
    "\n",
    "X_train_treated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline(steps=[\n",
    "    ('classifier', LogisticRegression(solver = 'lbfgs'))]\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'classifier__C': [0.1, 1],\n",
    "}\n",
    "\n",
    "cgm = GridSearchCV(clf, parameters, cv=5)\n",
    "\n",
    "cgm.fit(X_train_treated, y_train)\n",
    "\n",
    "cgm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.713"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = cgm.best_estimator_\n",
    "\n",
    "X_test_treated = transform.transform(X_test)\n",
    "\n",
    "est.score(X_test_treated, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this didn't achieve the optimal score (likely the `'filter_to_recommended': True` was too strict).  But it is in the ballpark and improves as we get more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
