{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Just for fun.\n",
    "\n",
    "Running a larger than is sensible example in the compositional vtreat exporter (in this case it makes more sense to use the update exporter as described [here](https://github.com/WinVector/pyvtreat/blob/main/Examples/Database/update_joins.ipynb))."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_algebra.data_ops import *\n",
    "import data_algebra.SQLite\n",
    "import data_algebra.test_util\n",
    "import vtreat\n",
    "from vtreat.vtreat_db_adapter import as_data_algebra_pipeline\n",
    "\n",
    "sys.setrecursionlimit(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# larger version of tests/test_db_adapter.py:test_db_adapter_monster()\n",
    "def mk_example(n_rows:int = 100, n_vars:int = 50):\n",
    "    step = 1/np.sqrt(n_vars)\n",
    "    cols = dict()\n",
    "    y = np.random.normal(size=n_rows)\n",
    "    for i in range(n_vars):\n",
    "        vname = f'v_{i}'\n",
    "        v = np.random.choice(['a', 'b'], replace=True, size=n_rows)\n",
    "        y = y + np.where(v == 'a', step, -step)\n",
    "        cols[vname] = v\n",
    "    vars = list(cols.keys())\n",
    "    vars.sort()\n",
    "    cols['y'] = y\n",
    "    d = pd.DataFrame(cols)\n",
    "\n",
    "    outcome_name = \"y\"\n",
    "    cols_to_copy = [outcome_name]\n",
    "    columns = vars + cols_to_copy\n",
    "\n",
    "    treatment = vtreat.NumericOutcomeTreatment(\n",
    "        cols_to_copy=cols_to_copy,\n",
    "        outcome_name=outcome_name,\n",
    "        params=vtreat.vtreat_parameters(\n",
    "            {\"sparse_indicators\": False, \"filter_to_recommended\": False,}\n",
    "        ),\n",
    "    )\n",
    "    d_train_treated = treatment.fit_transform(d)\n",
    "    transform_as_data = treatment.description_matrix()\n",
    "    source_descr = TableDescription(\n",
    "        table_name='d_app',\n",
    "        column_names=columns,\n",
    "    )\n",
    "    return {\n",
    "        'transform_as_data': transform_as_data,\n",
    "        'source_descr': source_descr,\n",
    "    }\n",
    "\n",
    "ex = mk_example(n_vars=500)\n",
    "source_descr = ex['source_descr']\n",
    "transform_as_data = ex['transform_as_data']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-16 10:27:57.488079\n",
      "2021-12-16 10:28:04.934592\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "ops = as_data_algebra_pipeline(\n",
    "    source=source_descr,\n",
    "    vtreat_descr=transform_as_data,\n",
    "    treatment_table_name='transform_as_data',\n",
    ")\n",
    "print(datetime.datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-16 10:28:04.938398\n",
      "1189598\n",
      "2021-12-16 10:28:16.759611\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "ops_str = str(ops)\n",
    "print(len(ops_str))\n",
    "del ops_str\n",
    "print(datetime.datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-16 10:28:16.764426\n",
      "62734179\n",
      "2021-12-16 10:33:22.756291\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "db_model = data_algebra.SQLite.SQLiteModel()\n",
    "sql_str = db_model.to_sql(ops)\n",
    "print(len(sql_str))\n",
    "del sql_str\n",
    "print(datetime.datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The point being: 62 million character SQL query is probably larger than any reasonable query size limit. Again, in this case we don't need to make this query as we can use the [update exporter](https://github.com/WinVector/pyvtreat/blob/main/Examples/Database/update_joins.ipynb) at this scale."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1  # show we are done"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}