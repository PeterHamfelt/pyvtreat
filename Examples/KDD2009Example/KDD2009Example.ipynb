{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an supervised classification example taken from the KDD 2009 cup.  A copy of the data and details can be found here: [https://github.com/WinVector/PDSwR2/tree/master/KDD2009](https://github.com/WinVector/PDSwR2/tree/master/KDD2009).  The problem was to predict account cancellation (\"churn\") from very messy data (column names not given, numeric and categorical variables, many missing values, some categorical variables with a large number of possible levels).  In this example we show how to quickly use `vtreat` to prepare the data for modeling.  `vtreat` takes in `Pandas` `DataFrame`s and returns both a treatment plan and a clean `Pandas` `DataFrame` ready for modeling."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To install:\n",
    "!pip install https://github.com/WinVector/pyvtreat/raw/master/pkg/dist/vtreat-0.1.tar.gz\n",
    "!pip install https://github.com/WinVector/wvpy/raw/master/pkg/dist/wvpy-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our packages/modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import xgboost\n",
    "import vtreat\n",
    "import numpy\n",
    "import numpy.random\n",
    "import wvpy.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in explanitory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 230)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# data from https://github.com/WinVector/PDSwR2/tree/master/KDD2009\n",
    "dir = \"../../../PracticalDataScienceWithR2nd/PDSwR2/KDD2009/\"\n",
    "d = pandas.read_csv(dir + 'orange_small_train.data.gz', sep='\\t', header=0)\n",
    "vars = [c for c in d.columns]\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dependent variable we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pandas.read_csv(dir + 'orange_small_train_churn.labels.txt', header=None)\n",
    "churn.columns = [\"churn\"]\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    46328\n",
       " 1     3672\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn[\"churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrange test/train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = d.shape[0]\n",
    "is_train = numpy.random.uniform(size=n)<=0.9\n",
    "is_test = numpy.logical_not(is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = d.loc[is_train, :].copy()\n",
    "churn_train = numpy.asarray(churn.loc[is_train, :][\"churn\"]==1)\n",
    "d_test = d.loc[is_test, :].copy()\n",
    "churn_test = numpy.asarray(churn.loc[is_test, :][\"churn\"]==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the dependent variables.  They are a mess, many missing values.  Categorical variables that can not be directly used without some re-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>fXVEsaq</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2Kb5FSF</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>NKv4yOc</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>CE7uk3u</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>1J2cvxe</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  Var10  ...  \\\n",
       "0   NaN   NaN   NaN   NaN   NaN  1526.0   7.0   NaN   NaN    NaN  ...   \n",
       "1   NaN   NaN   NaN   NaN   NaN   525.0   0.0   NaN   NaN    NaN  ...   \n",
       "2   NaN   NaN   NaN   NaN   NaN  5236.0   7.0   NaN   NaN    NaN  ...   \n",
       "3   NaN   NaN   NaN   NaN   NaN     NaN   0.0   NaN   NaN    NaN  ...   \n",
       "4   NaN   NaN   NaN   NaN   NaN  1029.0   7.0   NaN   NaN    NaN  ...   \n",
       "\n",
       "    Var221   Var222      Var223  Var224  Var225  Var226   Var227  \\\n",
       "0     oslk  fXVEsaq  jySVZNlOJy     NaN     NaN    xb3V     RAYp   \n",
       "1     oslk  2Kb5FSF  LM8l689qOp     NaN     NaN    fKCe     RAYp   \n",
       "2  Al6ZaUT  NKv4yOc  jySVZNlOJy     NaN    kG3k    Qu4f  02N6s8f   \n",
       "3     oslk  CE7uk3u  LM8l689qOp     NaN     NaN    FSa2     RAYp   \n",
       "4     oslk  1J2cvxe  LM8l689qOp     NaN    kG3k    FSa2     RAYp   \n",
       "\n",
       "          Var228  Var229  Var230  \n",
       "0  F2FyR07IdsN7I     NaN     NaN  \n",
       "1  F2FyR07IdsN7I     NaN     NaN  \n",
       "2  ib5G6X1eUxUn6    am7c     NaN  \n",
       "3  F2FyR07IdsN7I     NaN     NaN  \n",
       "4  F2FyR07IdsN7I    mj86     NaN  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45020, 230)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try building a model directly off this data (this will fail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame.dtypes for data must be int, float or bool.\n",
      "                Did not expect the data types in fields Var191, Var192, Var193, Var194, Var195, Var196, Var197, Var198, Var199, Var200, Var201, Var202, Var203, Var204, Var205, Var206, Var207, Var208, Var210, Var211, Var212, Var213, Var214, Var215, Var216, Var217, Var218, Var219, Var220, Var221, Var222, Var223, Var224, Var225, Var226, Var227, Var228, Var229\n"
     ]
    }
   ],
   "source": [
    "fitter = xgboost.XGBClassifier(n_estimators=10, max_depth=3, objective='binary:logistic')\n",
    "try:\n",
    "    fitter.fit(d_train, churn_train)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly prepare a data frame with none of these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our treatment plan, this has the `sklearn.pipeline.Pipeline` interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = vtreat.BinomialOutcomeTreatment(outcome_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.fit_transform()` to get a special copy of the treated training data that has cross-validated mitigations againsst nested model bias. We call this a \"cross frame.\" `.fit_transform()` is deliberately a different `DataFrame` than what would be returned by `.fit().transform()` (the `.fit().transform()` would damage the modeling effort due nested model bias, the `.fit_transform()` \"cross frame\" uses cross-validation techniques similar to \"stacking\" to mitigate these issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_frame = plan.fit_transform(d_train, churn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the new data.  This frame is guaranteed to be all numeric with no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1_is_bad</th>\n",
       "      <th>Var2_is_bad</th>\n",
       "      <th>Var3_is_bad</th>\n",
       "      <th>Var4_is_bad</th>\n",
       "      <th>Var5_is_bad</th>\n",
       "      <th>Var6_is_bad</th>\n",
       "      <th>Var7_is_bad</th>\n",
       "      <th>Var9_is_bad</th>\n",
       "      <th>Var10_is_bad</th>\n",
       "      <th>Var11_is_bad</th>\n",
       "      <th>...</th>\n",
       "      <th>Var228_logit_code</th>\n",
       "      <th>Var228_prevalence_code</th>\n",
       "      <th>Var228_lev_F2FyR07IdsN7I</th>\n",
       "      <th>Var228_lev_55YFVY9</th>\n",
       "      <th>Var228_lev_ib5G6X1eUxUn6</th>\n",
       "      <th>Var229_logit_code</th>\n",
       "      <th>Var229_prevalence_code</th>\n",
       "      <th>Var229_lev__NA_</th>\n",
       "      <th>Var229_lev_am7c</th>\n",
       "      <th>Var229_lev_mj86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>0.653110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.568236</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016271</td>\n",
       "      <td>0.653110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008444</td>\n",
       "      <td>0.568236</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051287</td>\n",
       "      <td>0.053754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024928</td>\n",
       "      <td>0.234118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>0.653110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.568236</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>0.653110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010853</td>\n",
       "      <td>0.196046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1_is_bad  Var2_is_bad  Var3_is_bad  Var4_is_bad  Var5_is_bad  \\\n",
       "0          1.0          1.0          1.0          1.0          1.0   \n",
       "1          1.0          1.0          1.0          1.0          1.0   \n",
       "2          1.0          1.0          1.0          1.0          1.0   \n",
       "3          1.0          1.0          1.0          1.0          1.0   \n",
       "4          1.0          1.0          1.0          1.0          1.0   \n",
       "\n",
       "   Var6_is_bad  Var7_is_bad  Var9_is_bad  Var10_is_bad  Var11_is_bad  ...  \\\n",
       "0          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "1          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "2          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "3          1.0          0.0          1.0           1.0           1.0  ...   \n",
       "4          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "\n",
       "   Var228_logit_code  Var228_prevalence_code  Var228_lev_F2FyR07IdsN7I  \\\n",
       "0          -0.004466                0.653110                         1   \n",
       "1           0.016271                0.653110                         1   \n",
       "2          -0.051287                0.053754                         0   \n",
       "3           0.018763                0.653110                         1   \n",
       "4           0.018763                0.653110                         1   \n",
       "\n",
       "   Var228_lev_55YFVY9  Var228_lev_ib5G6X1eUxUn6  Var229_logit_code  \\\n",
       "0                   0                         0           0.001157   \n",
       "1                   0                         0          -0.008444   \n",
       "2                   0                         1           0.024928   \n",
       "3                   0                         0           0.013898   \n",
       "4                   0                         0          -0.010853   \n",
       "\n",
       "   Var229_prevalence_code  Var229_lev__NA_  Var229_lev_am7c  Var229_lev_mj86  \n",
       "0                0.568236                1                0                0  \n",
       "1                0.568236                1                0                0  \n",
       "2                0.234118                0                1                0  \n",
       "3                0.568236                1                0                0  \n",
       "4                0.196046                0                0                1  \n",
       "\n",
       "[5 rows x 518 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45020, 518)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a recommended subset of the new derived variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>treatment</th>\n",
       "      <th>y_aware</th>\n",
       "      <th>PearsonR</th>\n",
       "      <th>significance</th>\n",
       "      <th>vcount</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Var1_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>2.744829e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Var2_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>8.001237e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Var3_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018557</td>\n",
       "      <td>8.231651e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Var4_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>2.266743e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Var5_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>2.765338e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Var6_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033480</td>\n",
       "      <td>1.199284e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Var7_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.028326</td>\n",
       "      <td>1.840568e-09</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Var9_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>2.744829e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Var10_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>2.765338e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Var11_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018557</td>\n",
       "      <td>8.231651e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Var12_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>4.503588e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Var13_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.028326</td>\n",
       "      <td>1.840568e-09</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Var14_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018557</td>\n",
       "      <td>8.231651e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Var16_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>2.765338e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Var17_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>2.266743e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Var18_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>2.266743e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Var19_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>2.266743e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Var21_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033480</td>\n",
       "      <td>1.199284e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Var22_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.032987</td>\n",
       "      <td>2.543755e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Var23_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>2.765338e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Var24_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>6.485295e-02</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Var25_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.032987</td>\n",
       "      <td>2.543755e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Var26_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>2.765338e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Var27_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>2.765338e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Var28_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033022</td>\n",
       "      <td>2.411202e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Var29_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>2.744829e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Var30_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>2.744829e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Var33_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>8.498495e-03</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Var34_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>8.001237e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Var35_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.032987</td>\n",
       "      <td>2.543755e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>Var224_lev__NA_</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>6.737991e-02</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Var225_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>4.854559e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Var225_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.051938</td>\n",
       "      <td>2.823827e-28</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Var225_lev__NA_</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.053415</td>\n",
       "      <td>8.185905e-30</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Var225_lev_ELof</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.042879</td>\n",
       "      <td>8.879368e-20</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Var225_lev_kG3k</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014902</td>\n",
       "      <td>1.566847e-03</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Var226_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>1.660234e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Var226_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>9.650760e-05</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Var226_lev_FSa2</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>7.679703e-10</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Var226_lev_Qu4f</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.011112</td>\n",
       "      <td>1.838685e-02</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Var226_lev_WqMG</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.002112</td>\n",
       "      <td>6.540761e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Var226_lev_szEZ</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014885</td>\n",
       "      <td>1.586732e-03</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Var226_lev_7P5s</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.019724</td>\n",
       "      <td>2.848332e-05</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Var226_lev_fKCe</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>8.766431e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Var226_lev_Aoh3</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.007883</td>\n",
       "      <td>9.441142e-02</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Var227_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.004749</td>\n",
       "      <td>3.136039e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Var227_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.047994</td>\n",
       "      <td>2.222881e-24</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Var227_lev_RAYp</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.049337</td>\n",
       "      <td>1.132996e-25</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Var227_lev_ZI9m</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.045578</td>\n",
       "      <td>3.832087e-22</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Var227_lev_6fzt</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.003964</td>\n",
       "      <td>4.003190e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Var228_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>3.961430e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Var228_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.063467</td>\n",
       "      <td>2.063870e-41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Var228_lev_F2FyR07IdsN7I</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.064031</td>\n",
       "      <td>4.020376e-42</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Var228_lev_55YFVY9</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.028115</td>\n",
       "      <td>2.423886e-09</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Var228_lev_ib5G6X1eUxUn6</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033358</td>\n",
       "      <td>1.446180e-12</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Var229_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.004341</td>\n",
       "      <td>3.569861e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Var229_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.060438</td>\n",
       "      <td>1.043924e-37</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Var229_lev__NA_</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>6.069882e-38</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Var229_lev_am7c</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.038002</td>\n",
       "      <td>7.268481e-16</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Var229_lev_mj86</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.034882</td>\n",
       "      <td>1.329469e-13</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     variable          treatment  y_aware  PearsonR  \\\n",
       "0                 Var1_is_bad  missing_indicator    False  0.005150   \n",
       "1                 Var2_is_bad  missing_indicator    False  0.018589   \n",
       "2                 Var3_is_bad  missing_indicator    False  0.018557   \n",
       "3                 Var4_is_bad  missing_indicator    False  0.019967   \n",
       "4                 Var5_is_bad  missing_indicator    False  0.017137   \n",
       "5                 Var6_is_bad  missing_indicator    False -0.033480   \n",
       "6                 Var7_is_bad  missing_indicator    False -0.028326   \n",
       "7                 Var9_is_bad  missing_indicator    False  0.005150   \n",
       "8                Var10_is_bad  missing_indicator    False  0.017137   \n",
       "9                Var11_is_bad  missing_indicator    False  0.018557   \n",
       "10               Var12_is_bad  missing_indicator    False  0.003558   \n",
       "11               Var13_is_bad  missing_indicator    False -0.028326   \n",
       "12               Var14_is_bad  missing_indicator    False  0.018557   \n",
       "13               Var16_is_bad  missing_indicator    False  0.017137   \n",
       "14               Var17_is_bad  missing_indicator    False  0.019967   \n",
       "15               Var18_is_bad  missing_indicator    False  0.019967   \n",
       "16               Var19_is_bad  missing_indicator    False  0.019967   \n",
       "17               Var21_is_bad  missing_indicator    False -0.033480   \n",
       "18               Var22_is_bad  missing_indicator    False -0.032987   \n",
       "19               Var23_is_bad  missing_indicator    False  0.017137   \n",
       "20               Var24_is_bad  missing_indicator    False -0.008702   \n",
       "21               Var25_is_bad  missing_indicator    False -0.032987   \n",
       "22               Var26_is_bad  missing_indicator    False  0.017137   \n",
       "23               Var27_is_bad  missing_indicator    False  0.017137   \n",
       "24               Var28_is_bad  missing_indicator    False -0.033022   \n",
       "25               Var29_is_bad  missing_indicator    False  0.005150   \n",
       "26               Var30_is_bad  missing_indicator    False  0.005150   \n",
       "27               Var33_is_bad  missing_indicator    False  0.012403   \n",
       "28               Var34_is_bad  missing_indicator    False  0.018589   \n",
       "29               Var35_is_bad  missing_indicator    False -0.032987   \n",
       "..                        ...                ...      ...       ...   \n",
       "488           Var224_lev__NA_          indicator    False  0.008621   \n",
       "489         Var225_logit_code         logit_code     True  0.003288   \n",
       "490    Var225_prevalence_code         prevalance    False  0.051938   \n",
       "491           Var225_lev__NA_          indicator    False  0.053415   \n",
       "492           Var225_lev_ELof          indicator    False -0.042879   \n",
       "493           Var225_lev_kG3k          indicator    False -0.014902   \n",
       "494         Var226_logit_code         logit_code     True  0.006528   \n",
       "495    Var226_prevalence_code         prevalance    False  0.018376   \n",
       "496           Var226_lev_FSa2          indicator    False  0.028986   \n",
       "497           Var226_lev_Qu4f          indicator    False -0.011112   \n",
       "498           Var226_lev_WqMG          indicator    False -0.002112   \n",
       "499           Var226_lev_szEZ          indicator    False -0.014885   \n",
       "500           Var226_lev_7P5s          indicator    False -0.019724   \n",
       "501           Var226_lev_fKCe          indicator    False -0.000732   \n",
       "502           Var226_lev_Aoh3          indicator    False -0.007883   \n",
       "503         Var227_logit_code         logit_code     True -0.004749   \n",
       "504    Var227_prevalence_code         prevalance    False  0.047994   \n",
       "505           Var227_lev_RAYp          indicator    False  0.049337   \n",
       "506           Var227_lev_ZI9m          indicator    False -0.045578   \n",
       "507           Var227_lev_6fzt          indicator    False -0.003964   \n",
       "508         Var228_logit_code         logit_code     True  0.003999   \n",
       "509    Var228_prevalence_code         prevalance    False  0.063467   \n",
       "510  Var228_lev_F2FyR07IdsN7I          indicator    False  0.064031   \n",
       "511        Var228_lev_55YFVY9          indicator    False -0.028115   \n",
       "512  Var228_lev_ib5G6X1eUxUn6          indicator    False -0.033358   \n",
       "513         Var229_logit_code         logit_code     True -0.004341   \n",
       "514    Var229_prevalence_code         prevalance    False  0.060438   \n",
       "515           Var229_lev__NA_          indicator    False  0.060635   \n",
       "516           Var229_lev_am7c          indicator    False -0.038002   \n",
       "517           Var229_lev_mj86          indicator    False -0.034882   \n",
       "\n",
       "     significance  vcount  recommended  \n",
       "0    2.744829e-01   193.0        False  \n",
       "1    8.001237e-05   193.0         True  \n",
       "2    8.231651e-05   193.0         True  \n",
       "3    2.266743e-05   193.0         True  \n",
       "4    2.765338e-04   193.0         True  \n",
       "5    1.199284e-12   193.0         True  \n",
       "6    1.840568e-09   193.0         True  \n",
       "7    2.744829e-01   193.0        False  \n",
       "8    2.765338e-04   193.0         True  \n",
       "9    8.231651e-05   193.0         True  \n",
       "10   4.503588e-01   193.0        False  \n",
       "11   1.840568e-09   193.0         True  \n",
       "12   8.231651e-05   193.0         True  \n",
       "13   2.765338e-04   193.0         True  \n",
       "14   2.266743e-05   193.0         True  \n",
       "15   2.266743e-05   193.0         True  \n",
       "16   2.266743e-05   193.0         True  \n",
       "17   1.199284e-12   193.0         True  \n",
       "18   2.543755e-12   193.0         True  \n",
       "19   2.765338e-04   193.0         True  \n",
       "20   6.485295e-02   193.0        False  \n",
       "21   2.543755e-12   193.0         True  \n",
       "22   2.765338e-04   193.0         True  \n",
       "23   2.765338e-04   193.0         True  \n",
       "24   2.411202e-12   193.0         True  \n",
       "25   2.744829e-01   193.0        False  \n",
       "26   2.744829e-01   193.0        False  \n",
       "27   8.498495e-03   193.0        False  \n",
       "28   8.001237e-05   193.0         True  \n",
       "29   2.543755e-12   193.0         True  \n",
       "..            ...     ...          ...  \n",
       "488  6.737991e-02    77.0        False  \n",
       "489  4.854559e-01    38.0        False  \n",
       "490  2.823827e-28    38.0         True  \n",
       "491  8.185905e-30    77.0         True  \n",
       "492  8.879368e-20    77.0         True  \n",
       "493  1.566847e-03    77.0         True  \n",
       "494  1.660234e-01    38.0        False  \n",
       "495  9.650760e-05    38.0         True  \n",
       "496  7.679703e-10    77.0         True  \n",
       "497  1.838685e-02    77.0        False  \n",
       "498  6.540761e-01    77.0        False  \n",
       "499  1.586732e-03    77.0         True  \n",
       "500  2.848332e-05    77.0         True  \n",
       "501  8.766431e-01    77.0        False  \n",
       "502  9.441142e-02    77.0        False  \n",
       "503  3.136039e-01    38.0        False  \n",
       "504  2.222881e-24    38.0         True  \n",
       "505  1.132996e-25    77.0         True  \n",
       "506  3.832087e-22    77.0         True  \n",
       "507  4.003190e-01    77.0        False  \n",
       "508  3.961430e-01    38.0        False  \n",
       "509  2.063870e-41    38.0         True  \n",
       "510  4.020376e-42    77.0         True  \n",
       "511  2.423886e-09    77.0         True  \n",
       "512  1.446180e-12    77.0         True  \n",
       "513  3.569861e-01    38.0        False  \n",
       "514  1.043924e-37    38.0         True  \n",
       "515  6.069882e-38    77.0         True  \n",
       "516  7.268481e-16    77.0         True  \n",
       "517  1.329469e-13    77.0         True  \n",
       "\n",
       "[518 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.score_frame_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vars = numpy.asarray(plan.score_frame_[\"variable\"][plan.score_frame_[\"recommended\"]])\n",
    "len(model_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = xgboost.DMatrix(data=cross_frame.loc[:, model_vars], label=churn_train)\n",
    "x_parameters = {\"max_depth\":3, \"objective\":'binary:logistic'}\n",
    "cv = xgboost.cv(x_parameters, fd, num_boost_round=100, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073634</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.073989</td>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.073612</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073723</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.073745</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073723</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.073745</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073723</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.073745</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0          0.073634         0.000878         0.073989        0.001630\n",
       "1          0.073467         0.000553         0.073612        0.001894\n",
       "2          0.073723         0.000881         0.073745        0.001667\n",
       "3          0.073723         0.000881         0.073745        0.001667\n",
       "4          0.073723         0.000881         0.073745        0.001667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.072268</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.073345</td>\n",
       "      <td>0.001353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.072323</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.073345</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "39          0.072268         0.000948         0.073345        0.001353\n",
       "40          0.072323         0.001045         0.073345        0.001455"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = cv.loc[cv[\"test-error-mean\"]<= min(cv[\"test-error-mean\"] + 1.0e-9), :]\n",
    "best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree = best.index.values[0]\n",
    "ntree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=3, min_child_weight=1, missing=None, n_estimators=39,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitter = xgboost.XGBClassifier(n_estimators=ntree, max_depth=3, objective='binary:logistic')\n",
    "fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fitter.fit(cross_frame.loc[:, model_vars], churn_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the data transform to our held-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed = plan.transform(d_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the quality of the model score on the held-out data.  This AUC is not great, but in the ballpark of the original contest winners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pf = pandas.DataFrame({\"churn\":churn_test})\n",
    "preds = model.predict_proba(test_processed.loc[:, model_vars])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf[\"pred\"] = preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.745153328062387"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvpy.util.plot_roc(pf[\"pred\"], pf[\"churn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we dealt with many problem columns at once, and in a statistically sound manner. More on the `vtreat` package for Python can be found here: [https://github.com/WinVector/pyvtreat](https://github.com/WinVector/pyvtreat).  Details on the `R` version can be found here: [https://github.com/WinVector/vtreat](https://github.com/WinVector/vtreat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to [R solution](https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
