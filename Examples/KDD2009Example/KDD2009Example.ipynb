{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an supervised classification example taken from the KDD 2009 cup.  A copy of the data and details can be found here: [https://github.com/WinVector/PDSwR2/tree/master/KDD2009](https://github.com/WinVector/PDSwR2/tree/master/KDD2009).  The problem was to predict account cancellation (\"churn\") from very messy data (column names not given, numeric and categorical variables, many missing values, some categorical variables with a large number of possible levels).  In this example we show how to quickly use `vtreat` to prepare the data for modeling.  `vtreat` takes in `Pandas` `DataFrame`s and returns both a treatment plan and a clean `Pandas` `DataFrame` ready for modeling."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To install:\n",
    "!pip install https://github.com/WinVector/pyvtreat/raw/master/pkg/dist/vtreat-0.1.tar.gz\n",
    "!pip install https://github.com/WinVector/wvpy/raw/master/pkg/dist/wvpy-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our packages/modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import xgboost\n",
    "import vtreat\n",
    "import numpy\n",
    "import numpy.random\n",
    "import wvpy.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in explanitory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 230)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# data from https://github.com/WinVector/PDSwR2/tree/master/KDD2009\n",
    "dir = \"../../../PracticalDataScienceWithR2nd/PDSwR2/KDD2009/\"\n",
    "d = pandas.read_csv(dir + 'orange_small_train.data.gz', sep='\\t', header=0)\n",
    "vars = [c for c in d.columns]\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dependent variable we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pandas.read_csv(dir + 'orange_small_train_churn.labels.txt', header=None)\n",
    "churn.columns = [\"churn\"]\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    46328\n",
       " 1     3672\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn[\"churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrange test/train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = d.shape[0]\n",
    "is_train = numpy.random.uniform(size=n)<=0.9\n",
    "is_test = numpy.logical_not(is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = d.loc[is_train, :].copy()\n",
    "churn_train = numpy.asarray(churn.loc[is_train, :][\"churn\"]==1)\n",
    "d_test = d.loc[is_test, :].copy()\n",
    "churn_test = numpy.asarray(churn.loc[is_test, :][\"churn\"]==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the dependent variables.  They are a mess, many missing values.  Categorical variables that can not be directly used without some re-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>fXVEsaq</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2Kb5FSF</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>CE7uk3u</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>658.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>QqVuch3</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Qcbd</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>Zy3gnGM</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>XlgxB9z</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  Var10  ...  Var221  \\\n",
       "0   NaN   NaN   NaN   NaN   NaN  1526.0   7.0   NaN   NaN    NaN  ...    oslk   \n",
       "1   NaN   NaN   NaN   NaN   NaN   525.0   0.0   NaN   NaN    NaN  ...    oslk   \n",
       "3   NaN   NaN   NaN   NaN   NaN     NaN   0.0   NaN   NaN    NaN  ...    oslk   \n",
       "5   NaN   NaN   NaN   NaN   NaN   658.0   7.0   NaN   NaN    NaN  ...    zCkv   \n",
       "6   NaN   NaN   NaN   NaN   NaN  1680.0   7.0   NaN   NaN    NaN  ...    oslk   \n",
       "\n",
       "    Var222      Var223  Var224  Var225  Var226   Var227         Var228  \\\n",
       "0  fXVEsaq  jySVZNlOJy     NaN     NaN    xb3V     RAYp  F2FyR07IdsN7I   \n",
       "1  2Kb5FSF  LM8l689qOp     NaN     NaN    fKCe     RAYp  F2FyR07IdsN7I   \n",
       "3  CE7uk3u  LM8l689qOp     NaN     NaN    FSa2     RAYp  F2FyR07IdsN7I   \n",
       "5  QqVuch3  LM8l689qOp     NaN     NaN    Qcbd  02N6s8f        Zy3gnGM   \n",
       "6  XlgxB9z  LM8l689qOp     NaN    kG3k    FSa2     RAYp        55YFVY9   \n",
       "\n",
       "   Var229  Var230  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "5    am7c     NaN  \n",
       "6    am7c     NaN  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44945, 230)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try building a model directly off this data (this will fail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame.dtypes for data must be int, float or bool.\n",
      "                Did not expect the data types in fields Var191, Var192, Var193, Var194, Var195, Var196, Var197, Var198, Var199, Var200, Var201, Var202, Var203, Var204, Var205, Var206, Var207, Var208, Var210, Var211, Var212, Var213, Var214, Var215, Var216, Var217, Var218, Var219, Var220, Var221, Var222, Var223, Var224, Var225, Var226, Var227, Var228, Var229\n"
     ]
    }
   ],
   "source": [
    "fitter = xgboost.XGBClassifier(n_estimators=10, max_depth=3, objective='binary:logistic')\n",
    "try:\n",
    "    fitter.fit(d_train, churn_train)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly prepare a data frame with none of these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our treatment plan, this has the `sklearn.pipeline.Pipeline` interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = vtreat.BinomialOutcomeTreatment(outcome_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.fit_transform()` to get a special copy of the treated training data that has cross-validated mitigations againsst nested model bias. We call this a \"cross frame.\" `.fit_transform()` is deliberately a different `DataFrame` than what would be returned by `.fit().transform()` (the `.fit().transform()` would damage the modeling effort due nested model bias, the `.fit_transform()` \"cross frame\" uses cross-validation techniques similar to \"stacking\" to mitigate these issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_frame = plan.fit_transform(d_train, churn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the new data.  This frame is guaranteed to be all numeric with no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1_is_bad</th>\n",
       "      <th>Var2_is_bad</th>\n",
       "      <th>Var3_is_bad</th>\n",
       "      <th>Var4_is_bad</th>\n",
       "      <th>Var5_is_bad</th>\n",
       "      <th>Var6_is_bad</th>\n",
       "      <th>Var7_is_bad</th>\n",
       "      <th>Var9_is_bad</th>\n",
       "      <th>Var10_is_bad</th>\n",
       "      <th>Var11_is_bad</th>\n",
       "      <th>...</th>\n",
       "      <th>Var228_logit_code</th>\n",
       "      <th>Var228_prevalence_code</th>\n",
       "      <th>Var228_lev_F2FyR07IdsN7I</th>\n",
       "      <th>Var228_lev_55YFVY9</th>\n",
       "      <th>Var228_lev_ib5G6X1eUxUn6</th>\n",
       "      <th>Var229_logit_code</th>\n",
       "      <th>Var229_prevalence_code</th>\n",
       "      <th>Var229_lev__NA_</th>\n",
       "      <th>Var229_lev_am7c</th>\n",
       "      <th>Var229_lev_mj86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>0.653243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016127</td>\n",
       "      <td>0.567627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007802</td>\n",
       "      <td>0.653243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>0.567627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.653243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016127</td>\n",
       "      <td>0.567627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007802</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>0.233864</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035182</td>\n",
       "      <td>0.087173</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.233864</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1_is_bad  Var2_is_bad  Var3_is_bad  Var4_is_bad  Var5_is_bad  \\\n",
       "0          1.0          1.0          1.0          1.0          1.0   \n",
       "1          1.0          1.0          1.0          1.0          1.0   \n",
       "2          1.0          1.0          1.0          1.0          1.0   \n",
       "3          1.0          1.0          1.0          1.0          1.0   \n",
       "4          1.0          1.0          1.0          1.0          1.0   \n",
       "\n",
       "   Var6_is_bad  Var7_is_bad  Var9_is_bad  Var10_is_bad  Var11_is_bad  ...  \\\n",
       "0          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "1          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "2          1.0          0.0          1.0           1.0           1.0  ...   \n",
       "3          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "4          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "\n",
       "   Var228_logit_code  Var228_prevalence_code  Var228_lev_F2FyR07IdsN7I  \\\n",
       "0           0.014860                0.653243                         1   \n",
       "1          -0.007802                0.653243                         1   \n",
       "2           0.056106                0.653243                         1   \n",
       "3          -0.007802                0.018801                         0   \n",
       "4           0.035182                0.087173                         0   \n",
       "\n",
       "   Var228_lev_55YFVY9  Var228_lev_ib5G6X1eUxUn6  Var229_logit_code  \\\n",
       "0                   0                         0           0.016127   \n",
       "1                   0                         0           0.008263   \n",
       "2                   0                         0           0.016127   \n",
       "3                   0                         0           0.008263   \n",
       "4                   1                         0           0.017039   \n",
       "\n",
       "   Var229_prevalence_code  Var229_lev__NA_  Var229_lev_am7c  Var229_lev_mj86  \n",
       "0                0.567627                1                0                0  \n",
       "1                0.567627                1                0                0  \n",
       "2                0.567627                1                0                0  \n",
       "3                0.233864                0                1                0  \n",
       "4                0.233864                0                1                0  \n",
       "\n",
       "[5 rows x 519 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44945, 519)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a recommended subset of the new derived variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>treatment</th>\n",
       "      <th>y_aware</th>\n",
       "      <th>PearsonR</th>\n",
       "      <th>significance</th>\n",
       "      <th>vcount</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Var1_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>2.306945e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Var2_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>7.645254e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Var3_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>7.645254e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Var4_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>5.238657e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Var5_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>5.562969e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Var6_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033637</td>\n",
       "      <td>9.823582e-13</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Var7_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.029793</td>\n",
       "      <td>2.660484e-10</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Var9_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>2.306945e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Var10_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>5.562969e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Var11_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>7.645254e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Var12_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>3.277772e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Var13_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.029793</td>\n",
       "      <td>2.660484e-10</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Var14_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>7.645254e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Var16_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>5.562969e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Var17_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>5.238657e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Var18_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>5.238657e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Var19_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>5.238657e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Var21_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033637</td>\n",
       "      <td>9.823582e-13</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Var22_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033766</td>\n",
       "      <td>8.055027e-13</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Var23_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>5.562969e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Var24_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.008831</td>\n",
       "      <td>6.116754e-02</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Var25_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033766</td>\n",
       "      <td>8.055027e-13</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Var26_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>5.562969e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Var27_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>5.562969e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Var28_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033801</td>\n",
       "      <td>7.630305e-13</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Var29_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>2.306945e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Var30_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>2.306945e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Var33_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>2.013322e-03</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Var34_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>7.645254e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Var35_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033766</td>\n",
       "      <td>8.055027e-13</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Var224_lev__NA_</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>7.182048e-02</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Var225_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>3.389655e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Var225_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.051976</td>\n",
       "      <td>2.857919e-28</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Var225_lev__NA_</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.053645</td>\n",
       "      <td>5.213538e-30</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Var225_lev_ELof</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.043707</td>\n",
       "      <td>1.860150e-20</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Var225_lev_kG3k</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014827</td>\n",
       "      <td>1.669673e-03</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Var226_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.010149</td>\n",
       "      <td>3.142537e-02</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Var226_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>1.259278e-05</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Var226_lev_FSa2</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.032475</td>\n",
       "      <td>5.724581e-12</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Var226_lev_Qu4f</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.013016</td>\n",
       "      <td>5.789984e-03</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Var226_lev_WqMG</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.002741</td>\n",
       "      <td>5.612266e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Var226_lev_szEZ</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.019152</td>\n",
       "      <td>4.896163e-05</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Var226_lev_7P5s</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.023223</td>\n",
       "      <td>8.486448e-07</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Var226_lev_Aoh3</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.003243</td>\n",
       "      <td>4.917415e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Var226_lev_fKCe</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>6.766070e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Var227_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.995818e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Var227_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.046244</td>\n",
       "      <td>1.030681e-22</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Var227_lev_RAYp</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.047532</td>\n",
       "      <td>6.614918e-24</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Var227_lev_ZI9m</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.043824</td>\n",
       "      <td>1.472863e-20</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Var227_lev_6fzt</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.004116</td>\n",
       "      <td>3.829157e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Var228_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.003598</td>\n",
       "      <td>4.456376e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Var228_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.061954</td>\n",
       "      <td>1.780582e-39</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Var228_lev_F2FyR07IdsN7I</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.062596</td>\n",
       "      <td>2.896303e-40</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Var228_lev_55YFVY9</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.028726</td>\n",
       "      <td>1.121562e-09</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Var228_lev_ib5G6X1eUxUn6</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.032517</td>\n",
       "      <td>5.373590e-12</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Var229_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.005041</td>\n",
       "      <td>2.852279e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Var229_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.058865</td>\n",
       "      <td>8.475848e-36</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Var229_lev__NA_</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.059045</td>\n",
       "      <td>5.222696e-36</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Var229_lev_am7c</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.036825</td>\n",
       "      <td>5.742840e-15</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Var229_lev_mj86</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.034146</td>\n",
       "      <td>4.457325e-13</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     variable          treatment  y_aware  PearsonR  \\\n",
       "0                 Var1_is_bad  missing_indicator    False  0.005654   \n",
       "1                 Var2_is_bad  missing_indicator    False  0.018656   \n",
       "2                 Var3_is_bad  missing_indicator    False  0.018656   \n",
       "3                 Var4_is_bad  missing_indicator    False  0.019077   \n",
       "4                 Var5_is_bad  missing_indicator    False  0.019011   \n",
       "5                 Var6_is_bad  missing_indicator    False -0.033637   \n",
       "6                 Var7_is_bad  missing_indicator    False -0.029793   \n",
       "7                 Var9_is_bad  missing_indicator    False  0.005654   \n",
       "8                Var10_is_bad  missing_indicator    False  0.019011   \n",
       "9                Var11_is_bad  missing_indicator    False  0.018656   \n",
       "10               Var12_is_bad  missing_indicator    False  0.004616   \n",
       "11               Var13_is_bad  missing_indicator    False -0.029793   \n",
       "12               Var14_is_bad  missing_indicator    False  0.018656   \n",
       "13               Var16_is_bad  missing_indicator    False  0.019011   \n",
       "14               Var17_is_bad  missing_indicator    False  0.019077   \n",
       "15               Var18_is_bad  missing_indicator    False  0.019077   \n",
       "16               Var19_is_bad  missing_indicator    False  0.019077   \n",
       "17               Var21_is_bad  missing_indicator    False -0.033637   \n",
       "18               Var22_is_bad  missing_indicator    False -0.033766   \n",
       "19               Var23_is_bad  missing_indicator    False  0.019011   \n",
       "20               Var24_is_bad  missing_indicator    False -0.008831   \n",
       "21               Var25_is_bad  missing_indicator    False -0.033766   \n",
       "22               Var26_is_bad  missing_indicator    False  0.019011   \n",
       "23               Var27_is_bad  missing_indicator    False  0.019011   \n",
       "24               Var28_is_bad  missing_indicator    False -0.033801   \n",
       "25               Var29_is_bad  missing_indicator    False  0.005654   \n",
       "26               Var30_is_bad  missing_indicator    False  0.005654   \n",
       "27               Var33_is_bad  missing_indicator    False  0.014567   \n",
       "28               Var34_is_bad  missing_indicator    False  0.018656   \n",
       "29               Var35_is_bad  missing_indicator    False -0.033766   \n",
       "..                        ...                ...      ...       ...   \n",
       "489           Var224_lev__NA_          indicator    False  0.008492   \n",
       "490         Var225_logit_code         logit_code     True -0.004510   \n",
       "491    Var225_prevalence_code         prevalance    False  0.051976   \n",
       "492           Var225_lev__NA_          indicator    False  0.053645   \n",
       "493           Var225_lev_ELof          indicator    False -0.043707   \n",
       "494           Var225_lev_kG3k          indicator    False -0.014827   \n",
       "495         Var226_logit_code         logit_code     True -0.010149   \n",
       "496    Var226_prevalence_code         prevalance    False  0.020598   \n",
       "497           Var226_lev_FSa2          indicator    False  0.032475   \n",
       "498           Var226_lev_Qu4f          indicator    False -0.013016   \n",
       "499           Var226_lev_WqMG          indicator    False -0.002741   \n",
       "500           Var226_lev_szEZ          indicator    False -0.019152   \n",
       "501           Var226_lev_7P5s          indicator    False -0.023223   \n",
       "502           Var226_lev_Aoh3          indicator    False -0.003243   \n",
       "503           Var226_lev_fKCe          indicator    False  0.001967   \n",
       "504         Var227_logit_code         logit_code     True  0.000002   \n",
       "505    Var227_prevalence_code         prevalance    False  0.046244   \n",
       "506           Var227_lev_RAYp          indicator    False  0.047532   \n",
       "507           Var227_lev_ZI9m          indicator    False -0.043824   \n",
       "508           Var227_lev_6fzt          indicator    False -0.004116   \n",
       "509         Var228_logit_code         logit_code     True -0.003598   \n",
       "510    Var228_prevalence_code         prevalance    False  0.061954   \n",
       "511  Var228_lev_F2FyR07IdsN7I          indicator    False  0.062596   \n",
       "512        Var228_lev_55YFVY9          indicator    False -0.028726   \n",
       "513  Var228_lev_ib5G6X1eUxUn6          indicator    False -0.032517   \n",
       "514         Var229_logit_code         logit_code     True -0.005041   \n",
       "515    Var229_prevalence_code         prevalance    False  0.058865   \n",
       "516           Var229_lev__NA_          indicator    False  0.059045   \n",
       "517           Var229_lev_am7c          indicator    False -0.036825   \n",
       "518           Var229_lev_mj86          indicator    False -0.034146   \n",
       "\n",
       "     significance  vcount  recommended  \n",
       "0    2.306945e-01   193.0        False  \n",
       "1    7.645254e-05   193.0         True  \n",
       "2    7.645254e-05   193.0         True  \n",
       "3    5.238657e-05   193.0         True  \n",
       "4    5.562969e-05   193.0         True  \n",
       "5    9.823582e-13   193.0         True  \n",
       "6    2.660484e-10   193.0         True  \n",
       "7    2.306945e-01   193.0        False  \n",
       "8    5.562969e-05   193.0         True  \n",
       "9    7.645254e-05   193.0         True  \n",
       "10   3.277772e-01   193.0        False  \n",
       "11   2.660484e-10   193.0         True  \n",
       "12   7.645254e-05   193.0         True  \n",
       "13   5.562969e-05   193.0         True  \n",
       "14   5.238657e-05   193.0         True  \n",
       "15   5.238657e-05   193.0         True  \n",
       "16   5.238657e-05   193.0         True  \n",
       "17   9.823582e-13   193.0         True  \n",
       "18   8.055027e-13   193.0         True  \n",
       "19   5.562969e-05   193.0         True  \n",
       "20   6.116754e-02   193.0        False  \n",
       "21   8.055027e-13   193.0         True  \n",
       "22   5.562969e-05   193.0         True  \n",
       "23   5.562969e-05   193.0         True  \n",
       "24   7.630305e-13   193.0         True  \n",
       "25   2.306945e-01   193.0        False  \n",
       "26   2.306945e-01   193.0        False  \n",
       "27   2.013322e-03   193.0         True  \n",
       "28   7.645254e-05   193.0         True  \n",
       "29   8.055027e-13   193.0         True  \n",
       "..            ...     ...          ...  \n",
       "489  7.182048e-02    77.0        False  \n",
       "490  3.389655e-01    38.0        False  \n",
       "491  2.857919e-28    38.0         True  \n",
       "492  5.213538e-30    77.0         True  \n",
       "493  1.860150e-20    77.0         True  \n",
       "494  1.669673e-03    77.0         True  \n",
       "495  3.142537e-02    38.0        False  \n",
       "496  1.259278e-05    38.0         True  \n",
       "497  5.724581e-12    77.0         True  \n",
       "498  5.789984e-03    77.0         True  \n",
       "499  5.612266e-01    77.0        False  \n",
       "500  4.896163e-05    77.0         True  \n",
       "501  8.486448e-07    77.0         True  \n",
       "502  4.917415e-01    77.0        False  \n",
       "503  6.766070e-01    77.0        False  \n",
       "504  9.995818e-01    38.0        False  \n",
       "505  1.030681e-22    38.0         True  \n",
       "506  6.614918e-24    77.0         True  \n",
       "507  1.472863e-20    77.0         True  \n",
       "508  3.829157e-01    77.0        False  \n",
       "509  4.456376e-01    38.0        False  \n",
       "510  1.780582e-39    38.0         True  \n",
       "511  2.896303e-40    77.0         True  \n",
       "512  1.121562e-09    77.0         True  \n",
       "513  5.373590e-12    77.0         True  \n",
       "514  2.852279e-01    38.0        False  \n",
       "515  8.475848e-36    38.0         True  \n",
       "516  5.222696e-36    77.0         True  \n",
       "517  5.742840e-15    77.0         True  \n",
       "518  4.457325e-13    77.0         True  \n",
       "\n",
       "[519 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.score_frame_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vars = numpy.asarray(plan.score_frame_[\"variable\"][plan.score_frame_[\"recommended\"]])\n",
    "len(model_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = xgboost.DMatrix(data=cross_frame.loc[:, model_vars], label=churn_train)\n",
    "x_parameters = {\"max_depth\":3, \"objective\":'binary:logistic'}\n",
    "cv = xgboost.cv(x_parameters, fd, num_boost_round=100, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073067</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.073268</td>\n",
       "      <td>0.004695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073145</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.073201</td>\n",
       "      <td>0.004642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073167</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.073134</td>\n",
       "      <td>0.004709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.073201</td>\n",
       "      <td>0.004642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073201</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.073201</td>\n",
       "      <td>0.004642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0          0.073067         0.002485         0.073268        0.004695\n",
       "1          0.073145         0.002397         0.073201        0.004642\n",
       "2          0.073167         0.002288         0.073134        0.004709\n",
       "3          0.073190         0.002317         0.073201        0.004642\n",
       "4          0.073201         0.002321         0.073201        0.004642"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.069819</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.072155</td>\n",
       "      <td>0.00449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "92          0.069819         0.002161         0.072155         0.00449"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = cv.loc[cv[\"test-error-mean\"]<= min(cv[\"test-error-mean\"] + 1.0e-9), :]\n",
    "best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree = best.index.values[0]\n",
    "ntree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=3, min_child_weight=1, missing=None, n_estimators=92,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitter = xgboost.XGBClassifier(n_estimators=ntree, max_depth=3, objective='binary:logistic')\n",
    "fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fitter.fit(cross_frame.loc[:, model_vars], churn_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the data transform to our held-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed = plan.transform(d_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the quality of the model score on the held-out data.  This AUC is not great, but in the ballpark of the original contest winners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pf = pandas.DataFrame({\"churn\":churn_test})\n",
    "preds = model.predict_proba(test_processed.loc[:, model_vars])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf[\"pred\"] = preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.725306231744577"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvpy.util.plot_roc(pf[\"pred\"], pf[\"churn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we dealt with many problem columns at once, and in a statistically sound manner. More on the `vtreat` package for Python can be found here: [https://github.com/WinVector/pyvtreat](https://github.com/WinVector/pyvtreat).  Details on the `R` version can be found here: [https://github.com/WinVector/vtreat](https://github.com/WinVector/vtreat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to [R solution](https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
