{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take another look at the concept of \"regression to mediocrity\" as described in Nina Zumel's great article [*Why Do We Plot Predictions on the x-axis?*](http://www.win-vector.com/blog/2019/09/why-do-we-plot-predictions-on-the-x-axis/).\n",
    "\n",
    "This time let's consider the issue from the point of view of multinomial classification (a concept discusssed [here](https://github.com/WinVector/pyvtreat/blob/master/Examples/Multinomial/MultinomialExample.md)).\n",
    "\n",
    "First we load our packages and generate some synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy.random\n",
    "import pandas\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.389409</td>\n",
       "      <td>-1.117456</td>\n",
       "      <td>indeterminate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.354096</td>\n",
       "      <td>-0.762580</td>\n",
       "      <td>indeterminate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.057603</td>\n",
       "      <td>1.278706</td>\n",
       "      <td>indeterminate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.400339</td>\n",
       "      <td>2.040186</td>\n",
       "      <td>indeterminate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.125245</td>\n",
       "      <td>1.051682</td>\n",
       "      <td>indeterminate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2              y\n",
       "0  0.389409 -1.117456  indeterminate\n",
       "1 -0.354096 -0.762580  indeterminate\n",
       "2 -0.057603  1.278706  indeterminate\n",
       "3 -0.400339  2.040186  indeterminate\n",
       "4 -0.125245  1.051682  indeterminate"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.seed(34524)\n",
    "\n",
    "N = 100\n",
    "\n",
    "df = pandas.DataFrame({\n",
    "    'x1': numpy.random.normal(size=N),\n",
    "    'x2': numpy.random.normal(size=N),\n",
    "    })\n",
    "noise = 0.25*numpy.random.normal(size=N)\n",
    "y = df.x1 + df.x2 + noise\n",
    "df['y'] = numpy.where(\n",
    "    y < -2, \n",
    "    'short opportunity', \n",
    "    numpy.where(\n",
    "        y > 2, \n",
    "        'long opportunity', \n",
    "        'indeterminate'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indeterminate        84\n",
       "short opportunity    10\n",
       "long opportunity      6\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please pretend this data is a record of stock market trading situations where we have determined (by peaking into the future, something quite easy to do with historic data) there is a large opportunity to make money buying security (called `long opportunity`) or a larger opportunity to make money selling a security (called `short opportunity`).\n",
    "\n",
    "Let's build a model using the two observable dependent variables `x1` and `x2`.  These are measurements that are available at the time of the proposed trade that we hope correlate with or \"predict\" the future trading result.  For our model we will use a simple multinomial logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vars = ['x1', 'x2']\n",
    "\n",
    "fitter = sklearn.linear_model.LogisticRegression(\n",
    "    solver = 'saga',\n",
    "    penalty = 'l2',\n",
    "    C = 1,\n",
    "    max_iter = 1000,\n",
    "    multi_class = 'multinomial')\n",
    "fitter.fit(df[model_vars], df['y'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then examing the model predictions on the training data itself (a *much* lower standard than evaluating the model on held out data!!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience functions for predicting and adding predictions to original data frame\n",
    "\n",
    "def add_predictions(d_prepared, model_vars, fitter):\n",
    "    pred = fitter.predict_proba(d_prepared[model_vars])\n",
    "    classes = fitter.classes_\n",
    "    d_prepared['prob_on_predicted_class'] = 0\n",
    "    d_prepared['prediction'] = None\n",
    "    for i in range(len(classes)):\n",
    "        cl = classes[i]\n",
    "        d_prepared[cl] = pred[:, i]\n",
    "        improved = d_prepared[cl] > d_prepared['prob_on_predicted_class']\n",
    "        d_prepared.loc[improved, 'prediction'] = cl\n",
    "        d_prepared.loc[improved, 'prob_on_predicted_class'] = d_prepared.loc[improved, cl]\n",
    "    return d_prepared\n",
    "\n",
    "def add_value_by_column(d_prepared, name_column, new_column):\n",
    "    vals = d_prepared[name_column].unique()\n",
    "    d_prepared[new_column] = None\n",
    "    for v in vals:\n",
    "        matches = d_prepared[name_column]==v\n",
    "        d_prepared.loc[matches, new_column] = d_prepared.loc[matches, v]\n",
    "    return d_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['prediction'] = fitter.predict(df[model_vars])\n",
    "df = add_predictions(df, model_vars, fitter)\n",
    "df = add_value_by_column(df, 'y', 'prob_on_correct_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prob_on_predicted_class</th>\n",
       "      <th>prediction</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>long opportunity</th>\n",
       "      <th>short opportunity</th>\n",
       "      <th>prob_on_correct_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.961999</td>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.961999</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.031837</td>\n",
       "      <td>0.961999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.919933</td>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.919933</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.076905</td>\n",
       "      <td>0.919933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.892118</td>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.892118</td>\n",
       "      <td>0.106681</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.892118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.818074</td>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.818074</td>\n",
       "      <td>0.181323</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.818074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.927103</td>\n",
       "      <td>indeterminate</td>\n",
       "      <td>0.927103</td>\n",
       "      <td>0.070774</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.927103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               y  prob_on_predicted_class     prediction  indeterminate  \\\n",
       "0  indeterminate                 0.961999  indeterminate       0.961999   \n",
       "1  indeterminate                 0.919933  indeterminate       0.919933   \n",
       "2  indeterminate                 0.892118  indeterminate       0.892118   \n",
       "3  indeterminate                 0.818074  indeterminate       0.818074   \n",
       "4  indeterminate                 0.927103  indeterminate       0.927103   \n",
       "\n",
       "   long opportunity  short opportunity prob_on_correct_class  \n",
       "0          0.006164           0.031837              0.961999  \n",
       "1          0.003162           0.076905              0.919933  \n",
       "2          0.106681           0.001201              0.892118  \n",
       "3          0.181323           0.000603              0.818074  \n",
       "4          0.070774           0.002123              0.927103  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_columns = ['y', 'prob_on_predicted_class', 'prediction', \n",
    "                  'indeterminate', 'long opportunity', \n",
    "                  'short opportunity', 'prob_on_correct_class']\n",
    "df[result_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to examine the relation of the model predictions to outcomes is a graphical table called a *confusion matrix*.  The [scikit learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) has states:\n",
    "\n",
    "> By definition a confusion matrix `C` is such that `C[i,j]` is equal to the number of observations known to be in group `i` but predicted to be in group `j`.\n",
    "\n",
    "and\n",
    "\n",
    "> Wikipedia and other references may use a different convention for axes.\n",
    "\n",
    "This means in the sckit learn convention the column-id is determined by the prediction.  This further means: as a visual point the horizontal position of cells in the scikit learn confusion matrix is determined by the prediction because matrices have the odd convention that the first index is row which specifies what vertical level one is refering to.\n",
    "\n",
    "Frankly we think scikit learn has the right rendering choice: consistency and legibility over convention. As Nina Zumel [demonstrated](http://www.win-vector.com/blog/2019/09/why-do-we-plot-predictions-on-the-x-axis/): there are good reasons to have predictions on the x-axis for plots, and the same holds for diagrams or matrices.\n",
    "\n",
    "So let's look at this confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  8,  0],\n",
       "       [ 1, 83,  0],\n",
       "       [ 0,  5,  1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(\n",
    "    y_true=df.y, \n",
    "    y_pred=df.prediction, \n",
    "    labels=['short opportunity', 'indeterminate', 'long opportunity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our claim is: the prediction is controlling left/right in this matrix and the actual value to be predicted is determining up/down.\n",
    "\n",
    "We can confirm this as we see there are 16 actual values of `y` that are not `intermediate` and only 4 values of `prediction` that are not intermediate.  As the rows of the confusion matrix match the `y`-totals and the columns of the confusion matrix match the `prediction` totals we can confirm the matrix is oriented as described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['y']!='indeterminate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['prediction']!='indeterminate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, if we are careful, we see the effect.\n",
    "\n",
    "Notice again that 16 actual values of `y` that are not `intermediate` and only 4 values of `prediction` that are not intermediate.  The model only identifies one fourth as many possible extreme situations or good trades as there actually work, *even* on its own training data.  This is not a pathology such as structure in the residuals, but instead (simple and expected) [regression to mediocrity](https://en.wikipedia.org/wiki/Regression_toward_the_mean), as [Nina Zumel already described](http://www.win-vector.com/blog/2019/09/why-do-we-plot-predictions-on-the-x-axis/) so well.  In the real data all outcome probabilities are zero or one, in the predictions things are a bit more blurry. This example is less clearn than Nina Zumel's, but driven by related processes.\n",
    "\n",
    "Of course one can try to adjust the per-class thesholds to find more potential trading opportunities: but the new opportunities found are going to likely be of lower quality than the ones identified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
